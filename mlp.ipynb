{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3t5NdwBFqhS8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Check if CUDA is available and set device to GPU if it is\n",
    "dgpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YsUDOAZIUfiG"
   },
   "outputs": [],
   "source": [
    "# Read the MPG dataset.\n",
    "csvPath = \"trainset.csv\"\n",
    "df = pd.read_csv(csvPath,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0d9vmeeyTzu0"
   },
   "outputs": [],
   "source": [
    "# Pandas to Numpy\n",
    "x = df.iloc[:,range(24)].values\n",
    "y = df.iloc[:,[24,25]].values  # regression\n",
    "\n",
    "# Numpy to PyTorch\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVrDQ3ddSOYH",
    "outputId": "f4bc4d05-ca4e-44e2-c68d-fa4c0e0d618c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: x size =torch.Size([9000, 24])\n",
      "Label: y size =torch.Size([9000, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data: x size ={x.shape}\")\n",
    "print(f\"Label: y size ={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Mibo_PDySU8Q"
   },
   "outputs": [],
   "source": [
    "# Create the MLP model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 18),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(18, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 2)\n",
    ")\n",
    "model = model.to(dgpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dVjfnBaYS9nH"
   },
   "outputs": [],
   "source": [
    "# PyTorch 2.0 Model ahead-of-time (AOT) compilation using the eager mode backend.\n",
    "model = torch.compile(model,backend=\"aot_eager\")\n",
    "\n",
    "# Define the loss function for regression\n",
    "loss_mse = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)   # Use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "swJIY3CCTMXm",
    "outputId": "4fd08240-9f95-49ae-d1a6-081fbcc7c859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 4089.818359375\n",
      "Epoch 10000, loss: 10.351186752319336\n",
      "Epoch 20000, loss: 8.503694534301758\n",
      "Epoch 30000, loss: 7.91792106628418\n",
      "Epoch 40000, loss: 7.414238929748535\n",
      "Epoch 50000, loss: 7.2318549156188965\n",
      "Epoch 60000, loss: 7.095175266265869\n",
      "Epoch 70000, loss: 6.889412879943848\n",
      "Epoch 80000, loss: 6.836796283721924\n",
      "Epoch 90000, loss: 6.57572078704834\n"
     ]
    }
   ],
   "source": [
    "x = x.to(dgpu)\n",
    "y = y.to(dgpu)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)   # Use Adam optimizer\n",
    "# Train for 100,000 epochs.\n",
    "for epoch in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    loss = loss_mse(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Display status every 100 epochs.\n",
    "    if epoch % 10000 == 0:\n",
    "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76J_vx96T-s3",
    "outputId": "f043b80e-714e-4308-fcfc-6682f5e7718b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([9000, 2])\n",
      "tensor([[35.0943, 45.9024],\n",
      "        [36.3593, 47.9790],\n",
      "        [77.7868, 75.0867],\n",
      "        [46.2200, 60.1785],\n",
      "        [77.5696, 76.8736],\n",
      "        [39.2631, 52.7232],\n",
      "        [74.7539, 83.4317],\n",
      "        [64.0380, 71.5518],\n",
      "        [55.8704, 61.9317],\n",
      "        [77.0808, 74.0154]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(x)\n",
    "print(f\"Shape: {pred.shape}\")\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JES9dSUfUUl_",
    "outputId": "a2f85a43-9d4a-423d-db9a-92298e268156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 2.6175897121429443\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(pred.cpu().detach(), y.cpu().detach()))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdK8nZJVUcsI",
    "outputId": "05d9bb35-62c1-4e36-d709-1c7de5b5429c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE) with training dataset: 2.617591619491577\n"
     ]
    }
   ],
   "source": [
    "score = torch.sqrt(torch.nn.functional.mse_loss(pred, y))\n",
    "print(f\"Final score (RMSE) with training dataset: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8AvnFhqUuaI",
    "outputId": "2457dd0e-7e55-4b74-ddd2-791cd1202408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Actual: tensor([32.9114, 43.6894], device='cuda:0'), Predicted: tensor([33.3982, 44.1787], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "2. Actual: tensor([33.5422, 43.5609], device='cuda:0'), Predicted: tensor([35.0445, 44.8536], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "3. Actual: tensor([77.3071, 75.7072], device='cuda:0'), Predicted: tensor([76.1236, 75.9842], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "4. Actual: tensor([46.6223, 60.6976], device='cuda:0'), Predicted: tensor([46.7042, 61.7231], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "5. Actual: tensor([77.0109, 77.1023], device='cuda:0'), Predicted: tensor([76.7840, 76.9242], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "6. Actual: tensor([39.9643, 50.4153], device='cuda:0'), Predicted: tensor([37.8064, 49.8892], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "7. Actual: tensor([78.2679, 73.2748], device='cuda:0'), Predicted: tensor([74.7063, 77.4578], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "8. Actual: tensor([62.4639, 71.1565], device='cuda:0'), Predicted: tensor([65.4410, 68.1239], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "9. Actual: tensor([53.5174, 63.5840], device='cuda:0'), Predicted: tensor([52.8802, 60.1727], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "10. Actual: tensor([74.8841, 76.3290], device='cuda:0'), Predicted: tensor([75.7114, 77.4997], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "11. Actual: tensor([55.0149, 62.6083], device='cuda:0'), Predicted: tensor([55.3556, 62.3578], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "12. Actual: tensor([63.7489, 65.5626], device='cuda:0'), Predicted: tensor([66.0550, 65.8127], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "13. Actual: tensor([75.6632, 79.3210], device='cuda:0'), Predicted: tensor([76.4016, 78.0404], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "14. Actual: tensor([54.3852, 64.3008], device='cuda:0'), Predicted: tensor([52.5733, 67.4420], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "15. Actual: tensor([53.7837, 73.1390], device='cuda:0'), Predicted: tensor([54.0186, 73.7856], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "16. Actual: tensor([65.2928, 67.1735], device='cuda:0'), Predicted: tensor([68.2082, 67.0515], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "17. Actual: tensor([65.5110, 79.7341], device='cuda:0'), Predicted: tensor([68.5992, 78.3796], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "18. Actual: tensor([61.9060, 73.8072], device='cuda:0'), Predicted: tensor([60.7402, 76.5076], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "19. Actual: tensor([83.7094, 76.0033], device='cuda:0'), Predicted: tensor([76.7665, 75.7268], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "20. Actual: tensor([77.7737, 76.6123], device='cuda:0'), Predicted: tensor([76.5378, 75.3992], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "21. Actual: tensor([67.6673, 77.3058], device='cuda:0'), Predicted: tensor([68.6816, 78.1455], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "22. Actual: tensor([42.8958, 50.0987], device='cuda:0'), Predicted: tensor([44.2813, 51.4975], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "23. Actual: tensor([64.7746, 63.1835], device='cuda:0'), Predicted: tensor([65.8463, 63.9313], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "24. Actual: tensor([40.4610, 50.8948], device='cuda:0'), Predicted: tensor([40.0218, 50.3473], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "25. Actual: tensor([68.3199, 75.0684], device='cuda:0'), Predicted: tensor([67.5944, 75.7327], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "26. Actual: tensor([62.0969, 69.7445], device='cuda:0'), Predicted: tensor([64.3040, 68.5861], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "27. Actual: tensor([53.4935, 80.5453], device='cuda:0'), Predicted: tensor([53.6819, 72.0764], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "28. Actual: tensor([69.7387, 69.2685], device='cuda:0'), Predicted: tensor([69.6549, 69.5581], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "29. Actual: tensor([45.8135, 59.1187], device='cuda:0'), Predicted: tensor([46.3563, 59.1211], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "30. Actual: tensor([46.3181, 57.4019], device='cuda:0'), Predicted: tensor([46.6184, 58.4242], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "31. Actual: tensor([64.2078, 67.0484], device='cuda:0'), Predicted: tensor([67.1229, 69.3943], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "32. Actual: tensor([55.9360, 64.9319], device='cuda:0'), Predicted: tensor([53.4105, 63.1132], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "33. Actual: tensor([65.4057, 79.2921], device='cuda:0'), Predicted: tensor([69.0624, 81.5649], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "34. Actual: tensor([76.4220, 75.9467], device='cuda:0'), Predicted: tensor([76.3567, 77.2853], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "35. Actual: tensor([77.6229, 78.1894], device='cuda:0'), Predicted: tensor([75.8633, 78.6518], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "36. Actual: tensor([54.4846, 64.6743], device='cuda:0'), Predicted: tensor([52.9033, 72.2946], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "37. Actual: tensor([51.2139, 63.2930], device='cuda:0'), Predicted: tensor([51.9756, 65.6540], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "38. Actual: tensor([43.4727, 51.6031], device='cuda:0'), Predicted: tensor([41.8046, 50.8511], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "39. Actual: tensor([58.4679, 79.0821], device='cuda:0'), Predicted: tensor([61.0113, 77.2361], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "40. Actual: tensor([48.1764, 54.9693], device='cuda:0'), Predicted: tensor([48.9150, 56.7930], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "41. Actual: tensor([45.0975, 58.9235], device='cuda:0'), Predicted: tensor([44.5642, 57.2185], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "42. Actual: tensor([49.4885, 60.9712], device='cuda:0'), Predicted: tensor([49.4738, 60.5732], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "43. Actual: tensor([75.4454, 77.7001], device='cuda:0'), Predicted: tensor([73.6599, 74.8620], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "44. Actual: tensor([34.9061, 45.2326], device='cuda:0'), Predicted: tensor([35.3375, 46.4015], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "45. Actual: tensor([45.7369, 54.8632], device='cuda:0'), Predicted: tensor([44.7784, 56.8457], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "46. Actual: tensor([53.3930, 77.9294], device='cuda:0'), Predicted: tensor([52.9988, 75.3414], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "47. Actual: tensor([76.8710, 76.7885], device='cuda:0'), Predicted: tensor([75.8233, 77.8635], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "48. Actual: tensor([38.6900, 50.9867], device='cuda:0'), Predicted: tensor([36.2319, 47.4565], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "49. Actual: tensor([60.0309, 76.1929], device='cuda:0'), Predicted: tensor([60.3426, 73.3640], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "50. Actual: tensor([78.2103, 75.8503], device='cuda:0'), Predicted: tensor([76.7332, 76.3772], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample predictions\n",
    "for i in range(50):\n",
    "    print(f\"{i+1}. Actual: {y[i]}, \" + f\"Predicted: {pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPW47NDFgdcB",
    "outputId": "187270e7-42e5-4ebe-dab1-3ea660f5e870"
   },
   "outputs": [],
   "source": [
    "csvPath = \"testset.csv\"\n",
    "df_test = pd.read_csv(csvPath)\n",
    "# Pandas to Numpy\n",
    "xt = df_test.iloc[:,range(24)].values\n",
    "yt = df_test.iloc[:,[24,25]].values  # regression\n",
    "\n",
    "# Numpy to PyTorch\n",
    "xt = torch.tensor(xt, dtype=torch.float32).to(dgpu)\n",
    "yt = torch.tensor(yt, dtype=torch.float32)\n",
    "\n",
    "# Pass into model\n",
    "yt_pred = model(xt).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlBNgNC3iB-j",
    "outputId": "4ce70034-d884-461e-fe0e-0fee05f3bb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE) with test set: 1.9144036769866943\n"
     ]
    }
   ],
   "source": [
    "score = torch.sqrt(torch.nn.functional.mse_loss(yt_pred, yt))\n",
    "print(f\"Final score (RMSE) with test set: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('pred.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(yt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([53.4241, 63.2120]) tensor([52.5213, 63.5209], grad_fn=<SelectBackward0>)\n",
      "tensor([36.6702, 45.9392]) tensor([35.8287, 45.3862], grad_fn=<SelectBackward0>)\n",
      "tensor([57.8885, 61.5989]) tensor([59.2745, 61.6897], grad_fn=<SelectBackward0>)\n",
      "tensor([80.0552, 75.1403]) tensor([75.7263, 77.0635], grad_fn=<SelectBackward0>)\n",
      "tensor([63.3119, 76.4552]) tensor([64.2205, 75.9043], grad_fn=<SelectBackward0>)\n",
      "tensor([75.9189, 72.5088]) tensor([72.8755, 71.9478], grad_fn=<SelectBackward0>)\n",
      "tensor([55.9193, 63.1268]) tensor([55.3061, 63.6761], grad_fn=<SelectBackward0>)\n",
      "tensor([75.9794, 76.5926]) tensor([76.1591, 78.1346], grad_fn=<SelectBackward0>)\n",
      "tensor([37.5860, 47.9917]) tensor([38.3881, 49.5250], grad_fn=<SelectBackward0>)\n",
      "tensor([64.5485, 60.7042]) tensor([65.1673, 60.7156], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(yt[i],yt_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
